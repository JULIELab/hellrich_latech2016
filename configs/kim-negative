CORPUS=/data/data_hellrich/google_books_parts/sampled/fiction
SIZE="1M" #e.g., 1M, all-5Y
WHAT="18{5..9}?_* 19??_* 2*_*"

TARGET="/home/hellrich/tmp/latech2016/fiction_kim_negative"
INDEPENDENT=false #false -> models are used to initialize each other

HS=0 #1 switches on hierarchic softmax
NEG=5 #default 5, ignored if HS=1
SAMPLE="1e-3" #default 1e-3

EPOCHS=10
CONVERGENCE="1e-4" #0 to train for full EPOCHS
MIN=10 #minimal occurrence per corpus part