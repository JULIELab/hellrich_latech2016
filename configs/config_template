CORPUS="/data/data_hellrich/google_books_parts/sampled/fictionA"
SIZE="1M" #e.g., 1M, all-5Y
WHAT="19??_*;2*_*" #"18{5..9}?_* 19??_* 2*_*"

TARGET="/home/hellrich/tmp/latech2016/fiction_5Y_hierarchical"
INDEPENDENT=false #false -> models are used to initialize each other

HS=0 #1 switches on hierarchic softmax
NEG=5 #default 5, ignored if HS=1
SAMPLE="1e-5" #default 1e-3

EPOCHS=10
CONVERGENCE="1e-4" #0 to train for full EPOCHS
MIN=10 #minimal occurrence per corpus part