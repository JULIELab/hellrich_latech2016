CORPUS=/data/data_hellrich/google_books_parts/sampled/german
SIZE="1M" #e.g., 1M, all-5Y
WHAT="185* 186* 187* 188* 189* 19* 2*"

TARGET="/home/hellrich/tmp/latech2016/fiction_kim_hierarchic_german"
INDEPENDENT=false #false -> models are used to initialize each other

HS=1 #1 switches on hierarchic softmax
NEG=0 #default 5, ignored if HS=1
SAMPLE="1e-3" #default 1e-3

EPOCHS=10
CONVERGENCE="1e-4" #0 to train for full EPOCHS
MIN=10 #minimal occurrence per corpus partALPHA=0.01
ALPHA=0.01
LOG=german_kim-hierarchic_
